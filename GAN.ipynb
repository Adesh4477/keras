{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size=256\n",
    "Buffer_size=60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(Buffer_size).batch(Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.002\n",
    "epochs=30\n",
    "image_dim=784\n",
    "gen_hid_dim=256\n",
    "dis_hid_dim=256\n",
    "z_noise_dim=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(shape):\n",
    "    return tf.random.normal(shape=shape,stddev=1./tf.sqrt(shape[0]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H=tf.Variable(xavier_init([image_dim,dis_hid_dim]))#weights\n",
    "disc_final=tf.Variable(xavier_init([dis_hid_dim,1]))\n",
    "gen_H=tf.Variable(xavier_init([z_noise_dim,gen_hid_dim]))\n",
    "gen_final=tf.Variable(xavier_init([gen_hid_dim,image_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H_b=tf.Variable(xavier_init([dis_hid_dim]))\n",
    "disc_final_b=tf.Variable(xavier_init([1]))\n",
    "gen_H_b=tf.Variable(xavier_init([gen_hid_dim]))\n",
    "gen_final_b=tf.Variable(xavier_init([image_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    hidden_layer=tf.nn.relu(tf.add(tf.matmul(x,disc_H),disc_H_b))\n",
    "    final_layer=tf.add(tf.matmul(hidden_layer,disc_final),disc_final_b)\n",
    "    output_layer=tf.nn.sigmoid(final_layer)\n",
    "    return final_layer,output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x):\n",
    "    hidden_layer=tf.nn.relu(tf.add(tf.matmul(x,gen_H),gen_H_b))\n",
    "    final_layer=tf.add(tf.matmul(hidden_layer,gen_final),gen_final_b)\n",
    "    output_layer=tf.nn.tanh(final_layer)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(101,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=generator_model()\n",
    "discriminator=discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset:\n",
    "    print(x.shape)\n",
    "    img=array_to_img(x[1].numpy())\n",
    "    img.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img=array_to_img(out.numpy().reshape(28,28,1))\n",
    "random_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=167, shape=(1, 1), dtype=float32, numpy=array([[0.9847296]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,r=discriminator(out)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output_disc,fake_output_disc):\n",
    "    disc_real_loss=-tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_output_disc,labels=tf.ones_like(real_output_disc)))\n",
    "    disc_fake_loss=-tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output_disc,labels=tf.zeros_like(fake_output_disc)))\n",
    "    total_loss=disc_real_loss+disc_fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output_disc):\n",
    "    disc_fake_loss=-tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output_disc,labels=tf.ones_like(fake_output_disc)))\n",
    "    return disc_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disc_real_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-169ce7b01b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisc_real_loss_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disc_real_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_real_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisc_fake_loss_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disc_fake_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_fake_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisc_total_loss_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disc_total_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgen_fake_loss_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gen_fake_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_fake_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'disc_real_loss' is not defined"
     ]
    }
   ],
   "source": [
    "disc_real_loss_summary=tf.summary.scalar(\"disc_real_loss\",disc_real_loss)\n",
    "disc_fake_loss_summary=tf.summary.scalar(\"disc_fake_loss\",disc_fake_loss)\n",
    "disc_total_loss_summary=tf.summary.scalar(\"disc_total_loss\",disc_total_loss)\n",
    "gen_fake_loss_summary=tf.summary.scalar(\"gen_fake_loss\",gen_fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer=tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "generator_optimizer=tf.keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise=tf.random.normal([Batch_size,z_noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images=generator(noise,training=True)\n",
    "        real_output=discriminator(images,training=True)\n",
    "        \n",
    "        fake_output=discriminator(generated_images,training=True)\n",
    "        gen_loss=generator_loss(fake_output)\n",
    "        disc_loss=discriminator_loss(real_output,fake_output)\n",
    "        \n",
    "    grad_of_gen=gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    grad_of_disc=disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(grad_of_gen,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(grad_of_disc,discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ex_to_gen=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([num_ex_to_gen, z_noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,epoch+1,seed)\n",
    "        \n",
    "        if (epoch + 1) % 15 == 0:\n",
    "              checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,epoch,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 8 is 401.1710114479065 sec\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
